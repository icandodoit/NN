{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB0h0Bzk6uB9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP-ENUEK7MHY"
      },
      "source": [
        "latent_dim = 100\n",
        "\n",
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    # block\n",
        "    def block(input_dim, output_dim, normalize=True):\n",
        "      layers = [nn.Linear(input_dim, output_dim)]\n",
        "      if normalize :\n",
        "        # 배치정규화\n",
        "          layers.append(nn.BatchNorm1d(output_dim, 0.8))\n",
        "      layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "      return layers\n",
        "\n",
        "    #여러개의 블록\n",
        "    self.model = nn.Sequential(\n",
        "        *block(latent_dim, 128, normalize = False),\n",
        "        *block(128, 256),\n",
        "        *block(256, 512),\n",
        "        *block(512, 1024),\n",
        "        nn.Linear(1024, 1*28*28),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "    \n",
        "    def forward(self, z):\n",
        "      img = self.model(z)\n",
        "      img = img.view(img.size(0),1,28,28)\n",
        "      return img"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLviyc8z9II3"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(1*28,28, 512),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(256, 1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "    def forward(self, img):\n",
        "      flattened = img.view( img.size(0), -1)\n",
        "      output = self.model(flattened)\n",
        "\n",
        "      return output"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNLcJnG_9ILb",
        "outputId": "ccc9c973-19ed-4d57-e925-5340ed7a9839"
      },
      "source": [
        "transforms_train = transforms.Compose([\n",
        "          transforms.Resize(28),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize([0.5],[0.5])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root = \"./dataset\", train = True, download  = True , transform = transforms_train)\n",
        "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size =128, shuffle =True, num_workers = 4)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k_Bf1xc9INu"
      },
      "source": [
        "# 초기화\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "generator.cuda()\n",
        "discriminator.cuda()\n",
        "\n",
        "# loss\n",
        "adversarial_loss = nn.BCELoss()\n",
        "adversarial_loss.cuda()\n",
        "\n",
        "# 학습률\n",
        "lr = 0.0002\n",
        "\n",
        "# 최적화 함수\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr , betas = (0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas = (0.5, 0.999))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "4X8KcjO9J7GQ",
        "outputId": "51e67cc5-1fc9-48cb-c086-bae1a2ca3ebc"
      },
      "source": [
        "import time\n",
        "n_epochs = 200 \n",
        "sample_interval = 2000\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(n_epochs) : \n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "      real = torch.cuda.FloatTensor(imgs.size(0),1).fill_(1.0) # 진짜(real) : 1\n",
        "      fake = torch.cuda.FloatTensor(imgs.size(0),1).fill_(0.0) # 가짜(fake) : 0\n",
        "\n",
        "      real_imgs = imgs.cuda()\n",
        "      \"\"\" 생성자 학습 \"\"\"\n",
        "      optimizer_G.zero_grad()\n",
        "\n",
        "      #랜덤 노이즈 샘플링\n",
        "      z = torch.normal(mean=0, std =1 , size=(imgs.shape[0],latent_dim)).cuda()\n",
        "\n",
        "      #이미지 생성\n",
        "      generated_imgs = generator(z)\n",
        "\n",
        "      #생성자(generator)의 손실(loss) 값 계산\n",
        "      g_loss = adversarial_loss(discriminator(generated_imgs), real)\n",
        "\n",
        "      # 생성자 업데이트\n",
        "      g_loss.backward()\n",
        "      optimizer_G.step()\n",
        "\n",
        "      \"\"\" 판별자 학습 \"\"\"\n",
        "      optimizer_D.zero_grad()\n",
        "\n",
        "      real_loss = adversarial_loss(discriminator(generated_imgs), real)\n",
        "      fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n",
        "      loss_d = (real_loss+fake_loss)/2  \n",
        "\n",
        "      d_loss.backward()\n",
        "      optimizer_D.step()\n",
        "\n",
        "      done = epoch *len(dataloader) + i \n",
        "      if done % sample_interval == 0 :\n",
        "        save_image(generated_imgs.data[:25], f\"{done}.png\", nrow=5, normalize=True)\n",
        "\n",
        "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss:{d_loss.item() :.6f}] [G loss: {g_loss.item():.6f}][Elapsed time: {time.time()-start_time:.2f}s]\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-75b66acbc45b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;31m#이미지 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mgenerated_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;31m#생성자(generator)의 손실(loss) 값 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNJ4D6ZUJ7Ir"
      },
      "source": [
        "  im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBE20f7YJ7LD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J10bVNG1J7NM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbBRLGeLJ7Pv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHth21gtJ7TV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}