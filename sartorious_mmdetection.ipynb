{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sartorious_mmdetection",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1yGR9eA_duBsmeKJeAB3o-_eFikkQfFxx",
      "authorship_tag": "ABX9TyM61cKpdQ695RB4h+AODyPu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icandodoit/Vision/blob/main/sartorious_mmdetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkwX47nTLUM_",
        "outputId": "688e6bc8-ad58-4521-fad2-4546d58f2e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openmim\n",
            "  Downloading openmim-0.1.5.tar.gz (35 kB)\n",
            "Requirement already satisfied: Click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from openmim) (7.1.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openmim) (2.23.0)\n",
            "Collecting model-index\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from openmim) (1.1.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from openmim) (0.8.9)\n",
            "Collecting ordered-set\n",
            "  Downloading ordered-set-4.0.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from model-index->openmim) (3.3.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from model-index->openmim) (3.13)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown->model-index->openmim) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->openmim) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (1.24.3)\n",
            "Building wheels for collected packages: openmim, ordered-set\n",
            "  Building wheel for openmim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openmim: filename=openmim-0.1.5-py2.py3-none-any.whl size=42502 sha256=bf71dd6dd90626d1881024982cc0386c7adb9c66d6cea739c2c7d40ab46d5920\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/8b/e1/bdebbbc687aa50224a5ce46fe97a040a0c59f92b34bfc750b6\n",
            "  Building wheel for ordered-set (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ordered-set: filename=ordered_set-4.0.2-py2.py3-none-any.whl size=8219 sha256=545a91d094e2243eeec3c93449987d51df103de3336f3aa768597d9939a9eb84\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/2b/f6/26e9f84153c25050fe7c09e88f8e32a6be3c7034a38c418319\n",
            "Successfully built openmim ordered-set\n",
            "Installing collected packages: ordered-set, model-index, colorama, openmim\n",
            "Successfully installed colorama-0.4.4 model-index-0.1.11 openmim-0.1.5 ordered-set-4.0.2\n",
            "installing mmdet from https://github.com/open-mmlab/mmdetection.git.\n",
            "Cloning into '/tmp/tmppxp1jv_q/mmdetection'...\n",
            "remote: Enumerating objects: 22371, done.\u001b[K\n",
            "remote: Total 22371 (delta 0), reused 0 (delta 0), pack-reused 22371\u001b[K\n",
            "Receiving objects: 100% (22371/22371), 25.47 MiB | 30.01 MiB/s, done.\n",
            "Resolving deltas: 100% (15659/15659), done.\n",
            "Note: checking out '5e246d5e3bc3310b5c625fb57bc03d2338ca39bc'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "\u001b[32minstalling dependency: mmcv-full\u001b[0m\n",
            "installing mmcv-full from wheel.\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
            "Collecting mmcv-full==1.4.1\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/mmcv_full-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (58.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 58.0 MB 14.8 MB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.4.1) (1.19.5)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.31.0-py2.py3-none-any.whl (185 kB)\n",
            "\u001b[K     |████████████████████████████████| 185 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.4.1) (7.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.4.1) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.4.1) (3.13)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.4.1) (4.1.2.30)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full==1.4.1) (3.0.6)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.4.1 yapf-0.31.0\n",
            "\u001b[32mSuccessfully installed mmcv-full.\u001b[0m\n",
            "\u001b[32mSuccessfully installed dependencies.\u001b[0m\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r /tmp/tmppxp1jv_q/mmdetection/requirements/build.txt (line 2)) (0.29.24)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /tmp/tmppxp1jv_q/mmdetection/requirements/build.txt (line 3)) (1.19.5)\n",
            "Processing /tmp/tmppxp1jv_q/mmdetection\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.19.1) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.19.1) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.19.1) (1.15.0)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet==2.19.1) (2.0.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.19.1) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.19.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.19.1) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.19.1) (2.8.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.19.1) (0.29.24)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.19.1) (57.4.0)\n",
            "Building wheels for collected packages: mmdet\n",
            "  Building wheel for mmdet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmdet: filename=mmdet-2.19.1-py3-none-any.whl size=1244321 sha256=fcc5b8ed02b3cd7b1eec4e4f8531b8b48d7da810347faf321c641723d2646eaa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gn0xca6x/wheels/61/9b/d4/30dc63e3f6b164fd679754dedb838a3a9a0ac8ebfef9004e4b\n",
            "Successfully built mmdet\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "Successfully installed mmdet-2.19.1 terminaltables-3.1.10\n",
            "\u001b[32mSuccessfully installed mmdet.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install openmim\n",
        "!mim install mmdet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import groupby\n",
        "from pycocotools import mask as mutils\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "from os import chdir as cd\n",
        "import os\n",
        "import pickle\n",
        "import cv2\n",
        "from multiprocessing import Pool\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JLIYCuDhMmqJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir ('/content/datasets/')"
      ],
      "metadata": {
        "id": "yQVstCBad0CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir ('/content/datasets/train')"
      ],
      "metadata": {
        "id": "6PeIFt-7QBx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir ('/content/datasets/val')"
      ],
      "metadata": {
        "id": "BC-RGFWyQP8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd ('/content/sartorius-cell-instance-segmentation/train')\n",
        "!unzip --qq  /content/drive/MyDrive/kaggle/annotations_train.json.zip"
      ],
      "metadata": {
        "id": "fouuea-YPSbn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd ('/content/sartorius-cell-instance-segmentation/train')\n",
        "!unzip --qq  /content/drive/MyDrive/kaggle/annotations_val.json.zip"
      ],
      "metadata": {
        "id": "uK95lHgBO3hS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#os.mkdir('/content/mmdetection')\n",
        "cd ('/content')\n",
        "!unzip --qq /content/drive/MyDrive/kaggle/mm2.19.0.zip"
      ],
      "metadata": {
        "id": "CijAU3omRRmZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir ('/content/sartorius-cell-instance-segmentation')\n",
        "cd ('/content/sartorius-cell-instance-segmentation')\n",
        "!unzip --qq /content/drive/MyDrive/kaggle/sartorius-cell-instance-segmentation.zip"
      ],
      "metadata": {
        "id": "nBQt_Q5cV2nA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir ('/content/datasets/train')"
      ],
      "metadata": {
        "id": "k4LAKn-OOcZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/mmdetection-2.19.0/configs/_base_/configs.py\n",
        "#coco seg\n",
        "dataset_type = 'CocoDataset'\n",
        "data_root = '/content/sartorius-cell-instance-segmentation/train'\n",
        "CLASSES = ('cort', 'shsy5y', 'astro')\n",
        "\n",
        "img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
        "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    dict(type='Normalize', **img_norm_cfg),\n",
        "    dict(type='Pad', size_divisor=32),\n",
        "    dict(type='SegRescale', scale_factor=1 / 8),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(\n",
        "        type='Collect',\n",
        "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks', 'gt_semantic_seg']),\n",
        "]\n",
        "test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=(1333, 800),\n",
        "        flip=False,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='RandomFlip', flip_ratio=0.5),\n",
        "            dict(type='Normalize', **img_norm_cfg),\n",
        "            dict(type='Pad', size_divisor=32),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img']),\n",
        "        ])\n",
        "]\n",
        "data = dict(\n",
        "    samples_per_gpu=2,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + '/train/annotations_train.json',\n",
        "        img_prefix=data_root + '',\n",
        "        seg_prefix=data_root + '',\n",
        "        pipeline=train_pipeline),\n",
        "    val=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + '/train/annotations_val.json',\n",
        "        img_prefix=data_root + '',\n",
        "        pipeline=test_pipeline),\n",
        "    test=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + '/train/annotations_val.json',\n",
        "        img_prefix=data_root + '',\n",
        "        pipeline=test_pipeline))\n",
        "evaluation = dict(metric=['bbox', 'segm'])\n",
        "\n",
        "\n",
        "\n",
        "# model settings mask_rcnn_fpn.py\n",
        "CLASSES = ('cort', 'shsy5y', 'astro')\n",
        "# model settings\n",
        "model = dict(\n",
        "    type='MaskRCNN',\n",
        "    backbone=dict(\n",
        "        type='ResNet',\n",
        "        depth=50,\n",
        "        num_stages=4,\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        frozen_stages=1,\n",
        "        norm_cfg=dict(type='BN', requires_grad=True),\n",
        "        norm_eval=True,\n",
        "        style='pytorch',\n",
        "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
        "    neck=dict(\n",
        "        type='FPN',\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5),\n",
        "    rpn_head=dict(\n",
        "        type='RPNHead',\n",
        "        in_channels=256,\n",
        "        feat_channels=256,\n",
        "        anchor_generator=dict(\n",
        "            type='AnchorGenerator',\n",
        "            scales=[4],\n",
        "            ratios=[0.5, 1.0, 2.0],\n",
        "            strides=[4, 8, 16, 32, 64]),\n",
        "        bbox_coder=dict(\n",
        "            type='DeltaXYWHBBoxCoder',\n",
        "            target_means=[.0, .0, .0, .0],\n",
        "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
        "    roi_head=dict(\n",
        "        type='StandardRoIHead',\n",
        "        bbox_roi_extractor=dict(\n",
        "            type='SingleRoIExtractor',\n",
        "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
        "            out_channels=256,\n",
        "            featmap_strides=[4, 8, 16, 32]),\n",
        "        bbox_head=dict(\n",
        "            type='Shared2FCBBoxHead',\n",
        "            in_channels=256,\n",
        "            fc_out_channels=1024,\n",
        "            roi_feat_size=7,\n",
        "            num_classes=3,\n",
        "            bbox_coder=dict(\n",
        "                type='DeltaXYWHBBoxCoder',\n",
        "                target_means=[0., 0., 0., 0.],\n",
        "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
        "            reg_class_agnostic=False,\n",
        "            loss_cls=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
        "        mask_roi_extractor=dict(\n",
        "            type='SingleRoIExtractor',\n",
        "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
        "            out_channels=256,\n",
        "            featmap_strides=[4, 8, 16, 32]),\n",
        "        mask_head=dict(\n",
        "            type='FCNMaskHead',\n",
        "            num_convs=4,\n",
        "            in_channels=256,\n",
        "            conv_out_channels=256,\n",
        "            num_classes=3,\n",
        "            loss_mask=dict(\n",
        "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
        "    # model training and testing settings\n",
        "    train_cfg=dict(\n",
        "        rpn=dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssigner',\n",
        "                pos_iou_thr=0.7,\n",
        "                neg_iou_thr=0.3,\n",
        "                min_pos_iou=0.3,\n",
        "                match_low_quality=True,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomSampler',\n",
        "                num=256,\n",
        "                pos_fraction=0.5,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=False),\n",
        "            allowed_border=-1,\n",
        "            pos_weight=-1,\n",
        "            debug=False),\n",
        "        rpn_proposal=dict(\n",
        "            nms_pre=2000,\n",
        "            max_per_img=1000,\n",
        "            nms=dict(type='nms', iou_threshold=0.7),\n",
        "            min_bbox_size=0),\n",
        "        rcnn=dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssigner',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                match_low_quality=True,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            mask_size=28,\n",
        "            pos_weight=-1,\n",
        "            debug=False)),\n",
        "    test_cfg=dict(\n",
        "        rpn=dict(\n",
        "            nms_pre=1000,\n",
        "            max_per_img=1000,\n",
        "            nms=dict(type='nms', iou_threshold=0.7),\n",
        "            min_bbox_size=0),\n",
        "        rcnn=dict(\n",
        "            score_thr=0.05,\n",
        "            nms=dict(type='nms', iou_threshold=0.5),\n",
        "            max_per_img=100,\n",
        "            mask_thr_binary=0.5)))\n",
        "load_from = \"https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\"\n",
        "\n",
        "# optimizer\n",
        "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
        "optimizer_config = dict(grad_clip=None)\n",
        "# learning policy\n",
        "lr_config = dict(\n",
        "    policy='step',\n",
        "    warmup='linear',\n",
        "    warmup_iters=500,\n",
        "    warmup_ratio=0.001,\n",
        "    step=[8, 11])\n",
        "runner = dict(type='EpochBasedRunner', max_epochs=96)\n",
        "\n",
        "\n",
        "\n",
        "##mmdetection/configs/_base_/default_runtime.py\n",
        "checkpoint_config = dict(interval=1)\n",
        "# yapf:disable\n",
        "log_config = dict(\n",
        "    interval=50,\n",
        "    hooks=[\n",
        "        dict(type='TextLoggerHook'),\n",
        "        # dict(type='TensorboardLoggerHook')\n",
        "    ])\n",
        "# yapf:enable\n",
        "custom_hooks = [dict(type='NumClassCheckHook')]\n",
        "\n",
        "dist_params = dict(backend='nccl')\n",
        "log_level = 'INFO'\n",
        "load_from = None\n",
        "resume_from = None\n",
        "workflow = [('train', 1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt5Yko0QRRyt",
        "outputId": "6cb6e56c-28af-42a5-aab7-100568abc5c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/mmdetection-2.19.0/configs/_base_/configs.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/mmdetection-2.19.0/tools/train.py /content/mmdetection-2.19.0/configs/_base_/configs.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9VGsfVYRR4G",
        "outputId": "b81533bd-5de6-474e-d159-c772bdc83884"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-21 05:49:18,614 - mmdet - INFO - Epoch [8][50/243]\tlr: 2.500e-03, eta: 4:41:00, time: 1.104, data_time: 0.650, memory: 8472, loss_rpn_cls: 0.1078, loss_rpn_bbox: 0.1440, loss_cls: 0.4471, acc: 80.5276, loss_bbox: 0.5591, loss_mask: 0.3518, loss: 1.6099\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/mmdetection-2.19.0/tools/train.py\", line 185, in <module>\n",
            "    main()\n",
            "  File \"/content/mmdetection-2.19.0/tools/train.py\", line 181, in main\n",
            "    meta=meta)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmdet/apis/train.py\", line 203, in train_detector\n",
            "    runner.run(data_loaders, cfg.workflow)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py\", line 127, in run\n",
            "    epoch_runner(data_loaders[i], **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py\", line 47, in train\n",
            "    for i, data_batch in enumerate(self.data_loader):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1186, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1152, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 990, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/mmdetection-2.19.0/tools/test.py /content/mmdetection-2.19.0/configs/_base_/configs.py /content/sartorius-cell-instance-segmentation/train/train/work_dirs/configs/epoch_6.pth --eval bbox segm\n"
      ],
      "metadata": {
        "id": "MtPuvg5kRR6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe55bf0b-b00b-4ebd-9174-0f430a31add4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.26s)\n",
            "creating index...\n",
            "index created!\n",
            "load checkpoint from local path: /content/sartorius-cell-instance-segmentation/train/train/work_dirs/configs/epoch_6.pth\n",
            "[>>] 121/121, 5.7 task/s, elapsed: 21s, ETA:     0s\n",
            "Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=33.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.19s).\n",
            "\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.128\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
            "\n",
            "\n",
            "Evaluating segm...\n",
            "/usr/local/lib/python3.7/dist-packages/mmdet/datasets/coco.py:443: UserWarning: The key \"bbox\" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.\n",
            "  UserWarning)\n",
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=33.36s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.19s).\n",
            "\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.132\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.132\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n",
            "\n",
            "OrderedDict([('bbox_mAP', 0.128), ('bbox_mAP_50', 0.295), ('bbox_mAP_75', 0.083), ('bbox_mAP_s', 0.131), ('bbox_mAP_m', 0.018), ('bbox_mAP_l', 0.0), ('bbox_mAP_copypaste', '0.128 0.295 0.083 0.131 0.018 0.000'), ('segm_mAP', 0.132), ('segm_mAP_50', 0.297), ('segm_mAP_75', 0.088), ('segm_mAP_s', 0.132), ('segm_mAP_m', 0.012), ('segm_mAP_l', 0.0), ('segm_mAP_copypaste', '0.132 0.297 0.088 0.132 0.012 0.000')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TjbmA878RR-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DCMPey6SRSAA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}